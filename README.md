# LLM을 사용하는 목적에 맞게 만들기
### 계기
- 번역에 관련된 일을 하던 중, 범용적인 LLM을 사용한 번역 결과는 특정 과제나 시기 등을 고려하지 않는 번역으로 예를 들어, 돈을 과거에는 조개껍데기, 엽전 등으로, 게임에서는 재화, 금화 등, 현대에서는 지폐, 동전, 수표 등으로 시대와 상황에 맞는 번역이 필요함을 느끼게 되었고 이런 과제를 해결하기 위한 연구를 하게 되었습니다.
### 구상중인 파이프라인
1. 사용자가 사용할 Base LLM 선택
    - 사용자의 컴퓨터 스펙, 사용할 목적에 맞는 Base LLM을 추천할 예정
2. 학습시킬 데이터 업로드
    - 모델에 따른 데이터 형식으로 자동 변환
3. Fine-Tuning 이후 추론 시 추가 요구사항을 프롬프트로 제공

### 방법
- SFT(Supervised Fine-Tuning) 지도학습 파인튜닝
    - 특정 도메인이나 작업에 최적화된 성능을 위한 추가 학습
    - 고품질의 라벨링된 데이터가 필요, 과적합 위험의 단점이 있음
- PEFT(Parameter-Efficient Fine-Tuning)
    - SFT의 방법중 하나
    - 특정 파라미터만을 업데이트하여 모델을 튜닝
- LoRA (Low-Rank Adaptation)
    - PEFT의 방법중 하나
    - 모델의 특정 층에서 저 차원 행렬을 사용하여 파라미터를 조정
- QLoRA (Quantized Low-Rank Adaptation)
    - LoRA 기법의 확장
    - 모델의 파라미터를 양자화하여 더욱 효율적인 튜닝 방법 
- RAG (Retrieval-Augmented Generation)
    - 자료를 검색하여 더욱 신뢰도 있는 답변을 출력